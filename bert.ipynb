{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:05.462063Z",
     "end_time": "2023-12-05T12:13:07.803995Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, AutoModelForMaskedLM, BertTokenizer, BertModel, BertConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:07.800677Z",
     "end_time": "2023-12-05T12:13:07.998384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:08.000383Z",
     "end_time": "2023-12-05T12:13:08.013408Z"
    }
   },
   "outputs": [],
   "source": [
    "#AutoConfig.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:08.015410Z",
     "end_time": "2023-12-05T12:13:08.059056Z"
    }
   },
   "outputs": [],
   "source": [
    "#BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "#config[]\n",
    "#BertModel.from_pretrained(\"bert-base-uncased\", max_position_embeddings = 64,ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:08.031475Z",
     "end_time": "2023-12-05T12:13:08.065144Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.cls.predictions.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#bert_model = BertModel.from_pretrained(\"bert-base-uncased\", max_position_embeddings = 64,ignore_mismatched_sizes=True)\n",
    "import copy\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\",output_hidden_states=True,return_dict=True)\n",
    "#bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "#bert_model = BertModel.from_pretrained(\"bert-base-uncased\", max_position_embeddings = 64,ignore_mismatched_sizes=True)\n",
    "ori_model = copy.deepcopy(bert_model)\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "frozen_model = copy.deepcopy(bert_model)\n",
    "from peft import LoraConfig, get_peft_model, PrefixTuningConfig\n",
    "lora_config = LoraConfig(\n",
    "r=8, #low rank\n",
    "lora_alpha=32, #alpha scalingï¼Œ scale lora weights/outputs\n",
    "# target_modules=[\"q_proj\", \"v_proj\"], #if you know the\n",
    "lora_dropout=0.1,\n",
    "#target_modules= [\"bert\"],\n",
    "task_type=\"MLM\" # set this for CLM or Seq2Seq\n",
    ")\n",
    "#ptuning_config = PrefixTuningConfig(task_type = \"SEQ_CLS\", num_virtual_tokens=10)\n",
    "lora_model = get_peft_model(bert_model, lora_config)\n",
    "#lora_model\n",
    "#ptuning_model = get_peft_model(bert_model, ptuning_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:08.046189Z",
     "end_time": "2023-12-05T12:13:09.179691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:09.178584Z",
     "end_time": "2023-12-05T12:13:09.194271Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegBert, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        #self.bert = model\n",
    "        #self.config = BertConfig()\n",
    "        #self.bert = BertModel.from_pretrained(\"bert-base-uncased\", max_position_embeddings = 512,ignore_mismatched_sizes=True)\n",
    "        #self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        #for param in self.bert.parameters():\n",
    "        #    param.requires_grad = False\n",
    "        #self.bert.cls.predictions.decoder = nn.Linear(in_features=768, out_features= 200, bias=True)\n",
    "        #self.fc1 = nn.Linear(768, 200)\n",
    "        self.model = frozen_model\n",
    "        #self.model = bert_model\n",
    "        #self.linear = nn.Linear(768*3, 2)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_ids, attention_mask = x[0].to(self.device), x[1].to(self.device)\n",
    "        hidden_out = self.model(input_ids, attention_mask=attention_mask, output_hidden_states=False)\n",
    "        # Use specific number of layers of hidden states of \"CLS\" token\n",
    "        #predict = self.linear(torch.concat(hidden_out.hidden_states[-3][:,0,:],-1))\n",
    "        #Use the last pooler output of \"CLS\" token, more commom in fine-tuning\n",
    "        predict = self.linear(hidden_out.pooler_output)\n",
    "        #predict = self.linear(hidden_out.hidden_states[-1])\n",
    "        return self.softmax(predict)\n",
    "        #return self.softmax(hidden_out.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#ori_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:09.192263Z",
     "end_time": "2023-12-05T12:13:09.211936Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "RegBert(\n  (model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear): Linear(in_features=768, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_model = RegBert()\n",
    "SA_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:09.208980Z",
     "end_time": "2023-12-05T12:13:09.394681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:09.394681Z",
     "end_time": "2023-12-05T12:13:10.223468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0215, -0.0151,  0.0165,  ..., -0.0312,  0.0163, -0.0182],\n",
      "        [-0.0237, -0.0077,  0.0143,  ...,  0.0146,  0.0277, -0.0028]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0075, -0.0154], device='cuda:0', requires_grad=True)\n",
      "trainable params: 1538 || all params: 109483778 || trainable%: 0.0014047743219091325\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(to_model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in to_model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "            print(param)\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "print_trainable_parameters(SA_model)\n",
    "\n",
    "#    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "#        param.data = param.data.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:10.224423Z",
     "end_time": "2023-12-05T12:13:10.268693Z"
    }
   },
   "outputs": [],
   "source": [
    "#a = tokenizer([\"yes, it is good\",\"asfaf\"])\n",
    "#a\n",
    "#SA_model(a[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:10.241611Z",
     "end_time": "2023-12-05T12:13:11.885745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 1600000 1600000\n"
     ]
    }
   ],
   "source": [
    "all_data = open(\"data.csv\", \"r\",encoding=\"utf-8\",errors=\"ignore\").read().split(\"\\n\")\n",
    "\n",
    "texts, labels, max_length = [], [], []\n",
    "for data in all_data:\n",
    "    if data:\n",
    "        line = data.split(\",\")\n",
    "        text = line[-1]\n",
    "        label = line[0]\n",
    "        max_length.append(len(text))\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "print(len(texts),len(labels),len(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:11.884662Z",
     "end_time": "2023-12-05T12:13:11.927841Z"
    }
   },
   "outputs": [],
   "source": [
    "#texts[0]\n",
    "#tokenizer(texts[0],truncation=True,padding=\"max_length\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:11.902062Z",
     "end_time": "2023-12-05T12:13:11.936454Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        output = tokenizer(texts[idx],truncation=True,padding=\"max_length\",max_length=512)\n",
    "        label = int(labels[idx].strip('\"'))\n",
    "        if label == 4:\n",
    "            label = 1\n",
    "        return (torch.tensor(output[\"input_ids\"]), torch.tensor(output[\"attention_mask\"])), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:11.915040Z",
     "end_time": "2023-12-05T12:13:11.936454Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TweetDataset(texts,labels)\n",
    "data_size = len(dataset)\n",
    "#dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-05T12:13:11.930053Z",
     "end_time": "2023-12-05T12:13:11.992743Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(data_size*0.6), int(data_size*0.2), int(data_size*0.2)])\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/120000 [00:08<5:50:21,  5.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m SA_model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_index, (batch_text, batch_label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(train_dataloader)):\n\u001B[1;32m---> 13\u001B[0m     batch_label \u001B[38;5;241m=\u001B[39m \u001B[43mbatch_label\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     pred \u001B[38;5;241m=\u001B[39m SA_model(batch_text)\n\u001B[0;32m     16\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, batch_label)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([para for para in SA_model.parameters() if para.requires_grad==True], lr= 0.01)\n",
    "acc_max = 0\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    loss_sum, count = 0, 0\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    SA_model.train()\n",
    "    for batch_index, (batch_text, batch_label) in enumerate(tqdm(train_dataloader)):\n",
    "        batch_label = batch_label.to(device)\n",
    "        pred = SA_model(batch_text)\n",
    "\n",
    "        loss = loss_fn(pred, batch_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss\n",
    "        count += 1\n",
    "        if count >= 1000:\n",
    "            print(\"Loss: {}\".format(loss_sum/count))\n",
    "            loss_sum, count = 0.0, 0\n",
    "        #if len(train_dataloader) - batch_index <= len(train_dataloader) % 1000 and count == len(train_dataloader) % 1000:\n",
    "        #    msg = \"[{0}/{1:5d}]\\tTrain_Loss:{2:.4f}\"\n",
    "        #    print(msg.format(epoch + 1, batch_index + 1, loss_sum / count))\n",
    "        #    loss_sum, count = 0.0, 0\n",
    "#\n",
    "        #if batch_index % 1000 == 999:\n",
    "        #    msg = \"[{0}/{1:5d}]\\tTrain_Loss:{2:.4f}\"\n",
    "        #    print(msg.format(epoch + 1, batch_index + 1, loss_sum / count))\n",
    "        #    loss_sum, count = 0.0, 0\n",
    "\n",
    "    SA_model.eval()\n",
    "    all_pred, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_text, batch_label in tqdm(valid_dataloader):\n",
    "            batch_label = batch_label.to(device)\n",
    "            pred = SA_model(batch_text)\n",
    "\n",
    "            pred = torch.argmax(pred, dim=1).cpu().numpy().tolist()\n",
    "            label = batch_label.cpu().numpy().tolist()\n",
    "\n",
    "            all_pred.extend(pred)\n",
    "            all_true.extend(label)\n",
    "\n",
    "    acc = accuracy_score(all_pred, all_true)\n",
    "    print(f\"dev acc:{acc:.4f}\")\n",
    "    wait = 0\n",
    "    if acc > acc_max:\n",
    "        print(acc, acc_max)\n",
    "        acc_max = acc\n",
    "        torch.save(SA_model.state_dict(), \"saved_dict/epoch{}_acc{}.pt\".format(epoch,acc))\n",
    "        print(f\"Best Model Saved\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= 3:\n",
    "            break\n",
    "\n",
    "torch.save(SA_model.state_dict(), \"saved_dict/final.pt\")\n",
    "costtime = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-16T19:22:13.281634Z",
     "end_time": "2023-10-16T19:22:13.347681Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-16T19:22:32.442413Z",
     "end_time": "2023-10-16T19:22:32.467565Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-17T00:50:03.495021Z",
     "end_time": "2023-10-17T00:50:03.512020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_pred, all_true = [], []\n",
    "from sklearn.metrics import accuracy_score\n",
    "SA_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_text, batch_label in tqdm(test_dataloader):\n",
    "        #print(batch_text, batch_label)\n",
    "        batch_label = batch_label.to(device)\n",
    "        pred = SA_model(batch_text)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        pred = pred.cpu().numpy().tolist()\n",
    "        label = batch_label.cpu().numpy().tolist()\n",
    "\n",
    "        all_pred.extend(pred)\n",
    "        all_true.extend(label)\n",
    "\n",
    "accuracy = accuracy_score(all_true, all_pred)\n",
    "\n",
    "print(f\"test dataset accuracy:{accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-25T16:43:53.211906Z",
     "end_time": "2023-11-25T17:37:43.575889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
